---
title: 概率导论 第二章 离散随机变量
date: 2021-01-02 14:00:08
tags: discrete random vairables
category: statistics
mathjax: True
---

#### 随机变量相关概念

 - 随机变量是试验结果的实值函数
 - 随机变量函数的函数定义了另一个随机变量
 - 对于一个随机变量，我们可以定义一些平均量，例如均值和方差
 - 可以在某事件或某随机变量的条件下定义一个随机变量
 - 存在一个随机变量与某事件或某随机变量相互独立的概念

#### 离散随机变量相关概念

 - 离散随机变量是试验结果的一个实值函数，但是它的取值范围只能是有限多个值或可数无限多个值
 - 一个离散随机变量有一个分布列，它对于随机变量的每一个取值，给出一个概率
 - 离散随机变量的函数也是一个离散随机变量，它的分布列可以从原随机变量的分布列得到

#### 典型的离散随机变量

 - 伯努利随机变量
   - 只具有两个状态，一般为其取值1和0表示发生和没有发生
 - 二项随机变量
   - 由n个伯努利随机变量组成
   - 事件取值由0到n
 - 几何随机变量
   - 在连续的伯努利试验中，令X表示直到第一次出现1时需要的次数，X就称为几何随机变量。
 - 泊松随机变量
   - 播送随机变量是对二项随机变量的近似
   - $\lambda = np$

##### 期望、均值和方差

 - 期望：$E[x]=\sum \limits_{x}xp_X(x)$
 - 方差：$var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$
 - 标准差：$\sigma_X = \sqrt{var(X)}$

#### 随机变量的函数

 - 随机变量的函数也是一个随机变量，其分布列可以通过其随机变量求出
   - $Y = g(x) = ax+b$
   - $p_Y(y) = \sum_{x|y=g(x)} p_x(x)$

##### 期望、均值和方差

 - 期望：$E[g(x)]=\sum \limits_{x}g(x)p_X(x)$
 - 方差：$var(g(X)) = E[(g(X) - E[g(X)])^2] = \sum \limits_{x}(g(x) - E[g(x)])^2p_X(x)$
 - 标准差：$\sigma_X = \sqrt{var(X)}$

##### 线性函数的均值和方差

 - 给定$Y = aX + b$
   - 期望：$E[Y] = aE[X] + b$
   - 方差：$var(Y) = a^2 var(X)$

#### 多个随机变量的联合分布列

 - 多个随机变量是指在同一个试验结果下产生的多个随机变量
   - 设X和Y为在某个试验中的随机变量
      - X和Y的联合分布列$p_{X,Y}(x,y)=P(X=x, Y=y)$
           - X和Y的边缘分布列：
              $$p_X(x) = \sum\limits_{y}p_{X,Y}(x,y)$$
                    $$p_Y(y) = \sum\limits_{x}p_{X,Y}(x,y)$$
                - X和Y的函数$g(X,Y)$是一个随机变量
                  $E[g(x,y)]=\sum\limits_{X}\sum\limits_{Y}(x,y)p_{X,Y}(x,y)$$

#### 条件

 - 设X和Y为某一试验中的两个随机变量
   - 设A为某事件，$P(A)>0$, 随机变量X在给定A发生的条件下的条件分布列$P_{X|A} = P(X=x|A)$并且满足$\sum\limits_{x}P_{X|A}(X)=1$
   - 设$A_1, \dots ,A_n$是一组互不相容事件，并且形成样本分割，且每一个事件概率不为0，则$p_X(x)=\sum\limits_{i=1}^{n}p_{X|A_i}(X=x|A_i)=\sum\limits_{i=1}^{n}p(X=x|A_i)p(A_i)$
   - 给定$Y=y$的条件下X的条件分布列与联合分布列之间：$p_{X,Y}(x,y)=p_Y(y)p_{X|Y}(x|y)$
   - 给定Y之下的X的条件分布列可以通过下列公式得到边缘分布列 $p_{X}(x)=\sum \limits_{y\in Y}P_{X|Y}(x|y)P_Y(y)$

##### 条件期望

 - 设X和Y为某一试验中的两个随机变量
   - 设A为某事件，$P(A)>0$.随机变量X在给定A发生的条件下的条件期望为$$E[X|A]=\sum\limits_{x} xP_{X|A}(x|A)$$
     对于函数$g(x)$, $E[g(X)|A]=\sum\limits_x g(x)p_{x|A}(x|A)$
 - 给定$Y=y$的条件下X的条件期望：$E[X|Y=y]=\sum\limits_xxp_{X,Y}(x|y)$
 - 设$A_1, \dots ,A_n$是一组互不相容事件，并且形成样本分割，且每一个事件概率不为0,则$E[X]=\sum\limits_{i=1}^{n}p(A_i)E[X|A_i]$,进一步假定事件B满足对一切i,$P(A_i\bigcap B)>0$,则$E[X|B]=\sum\limits_{i=1}^{n}p(A_i|B)E[X|A_i\bigcap B]$
 - 全期望定理： $$E[X]=\sum\limits_yp_Y(y)E[X|Y=y]$$

 #### 独立性

 ##### 随机变量与事件的独立性

 随机变量与事件的独立性的概念与两个事件的相互独立性的概念是相同的。其基本思想是刻画条件的事件的发生与否不会对随机变量取值提供新的信息。

 随机变量X独立于事件A指 $P(X=x\ and\ A) = P(X=x)P(A)=p_{X}(x)p(A)$

并可得出$P(X=x\ and\ A)=p_{X|A}(x)P(A)$和$P_{X|A}(x)=p_X(x)$

##### 随机变量之间的相互独立

如果随机变量X和Y称为相互独立，则它们满足$$p_{X,Y}(x,y)=p_X(x)p_Y(y)$$对一切x和y成立。并等价于$$p_{X|Y}(x|y)=p_{X}(x)p_{Y}(y)$$对一切x和一切满足$p_Y(y)>0$的y成立。

且随机变量X和Y的函数也相互独立：
$$E[g(X)h(Y)]=E[g(X)]E[h(Y)]$$

如果随机变量X和Y相互独立，则$$E[XY]=E[X]E[Y]$$
$$var(X+Y) = var(X)+var(Y)$$

